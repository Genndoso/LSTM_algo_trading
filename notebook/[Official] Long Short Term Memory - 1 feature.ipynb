{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T16:18:35.023530Z",
     "start_time": "2019-03-05T16:18:34.170695Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List all device\n",
    "from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T16:18:35.378639Z",
     "start_time": "2019-03-05T16:18:35.025077Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check available GPU\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T16:18:35.382332Z",
     "start_time": "2019-03-05T16:18:35.380129Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "# The GPU id to use, usually either \"0\" or \"1\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T16:18:35.513265Z",
     "start_time": "2019-03-05T16:18:35.384484Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Reshape, Lambda\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.activations import softmax\n",
    "from keras.optimizers import SGD\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T16:18:35.611625Z",
     "start_time": "2019-03-05T16:18:35.516763Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"../data/dowjones_calculated/periods.txt\", \"rb\") as fp:   # Unpickling\n",
    "    dataset = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T16:18:35.651753Z",
     "start_time": "2019-03-05T16:18:35.615552Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_train = dataset[0][0][0]['AABA'].values\n",
    "# meanX = X_train.mean(axis=1)\n",
    "# stdX = X_train.std(axis = 1)\n",
    "# X_train = X_train.sub(meanX, axis=0)\n",
    "# X_train = X_train.div(stdX, axis = 0)\n",
    "# X_train = X_train.values\n",
    "\n",
    "# X_train = dataset[0][0][0].values\n",
    "# X_train = (X_train - X_train.mean())/X_train.std()\n",
    "# y_train = dataset[0][0][1]['AABA'].values\n",
    "\n",
    "# returns = dataset[1][0][0]\n",
    "# returns = (returns - returns.mean()) / returns.std()\n",
    "X_test = dataset[1][0][0].values\n",
    "y_test = dataset[1][0][1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T16:18:35.756996Z",
     "start_time": "2019-03-05T16:18:35.657110Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = dataset[0][0][0]\n",
    "meanX = X_train.mean(axis=1)\n",
    "stdX = X_train.std(axis = 1)\n",
    "X_train = X_train.sub(meanX, axis=0)\n",
    "X_train = X_train.div(stdX, axis = 0)\n",
    "X_train = X_train.values\n",
    "\n",
    "y_train = dataset[0][0][1].values\n",
    "\n",
    "X_test = dataset[1][0][0].values\n",
    "y_test = dataset[1][0][1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T16:18:35.805670Z",
     "start_time": "2019-03-05T16:18:35.758249Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_one_hot(targets, nb_classes):\n",
    "    res = np.eye(nb_classes)[np.array(targets).reshape(-1)]\n",
    "    return res.reshape(list(targets.shape)+[nb_classes])\n",
    "y_train = get_one_hot(y_train, 2)\n",
    "y_test = get_one_hot(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T16:18:35.873270Z",
     "start_time": "2019-03-05T16:18:35.811074Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train shape: (750, 31)\n",
      "y train shape: (750, 31, 2)\n",
      "x test shape: (490, 31)\n",
      "y test shape: (490, 31, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"x train shape: {X_train.shape}\")\n",
    "print(f\"y train shape: {y_train.shape}\")\n",
    "print(f\"x test shape: {X_test.shape}\")\n",
    "print(f\"y test shape: {y_test.shape}\")\n",
    "# print(f\"predicted shape: {predicted.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T16:18:35.935233Z",
     "start_time": "2019-03-05T16:18:35.877864Z"
    }
   },
   "outputs": [],
   "source": [
    "timestep = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T16:18:36.005473Z",
     "start_time": "2019-03-05T16:18:35.936414Z"
    }
   },
   "outputs": [],
   "source": [
    "data = X_train\n",
    "targets = y_train\n",
    "\n",
    "train_gen = TimeseriesGenerator(data, targets,\n",
    "                               length=timestep, sampling_rate=1,\n",
    "                               batch_size=740)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T16:18:36.073289Z",
     "start_time": "2019-03-05T16:18:36.010680Z"
    }
   },
   "outputs": [],
   "source": [
    "data = X_test\n",
    "targets = y_test\n",
    "\n",
    "test_gen = TimeseriesGenerator(data, targets,\n",
    "                               length=timestep, sampling_rate=1,\n",
    "                               batch_size=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T16:18:36.166386Z",
     "start_time": "2019-03-05T16:18:36.081946Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = train_gen[0][0]\n",
    "y_train = train_gen[0][1]\n",
    "X_test = test_gen[0][0]\n",
    "y_test = test_gen[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T16:18:36.209848Z",
     "start_time": "2019-03-05T16:18:36.167862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train shape: (740, 10, 31)\n",
      "y train shape: (740, 31, 2)\n",
      "x test shape: (250, 10, 31)\n",
      "y test shape: (250, 31, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"x train shape: {X_train.shape}\")\n",
    "print(f\"y train shape: {y_train.shape}\")\n",
    "print(f\"x test shape: {X_test.shape}\")\n",
    "print(f\"y test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T16:18:36.278713Z",
     "start_time": "2019-03-05T16:18:36.214830Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train.transpose((0,2,1))\n",
    "X_train = np.reshape(X_train, (740 * 31, timestep))\n",
    "y_train = np.reshape(y_train, (740 * 31, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T16:18:36.364951Z",
     "start_time": "2019-03-05T16:18:36.284109Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reshaping X_train for efficient modelling\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "# X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T16:18:36.447368Z",
     "start_time": "2019-03-05T16:18:36.367150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train shape: (22940, 10, 1)\n",
      "y train shape: (22940, 2)\n",
      "x test shape: (250, 10, 31)\n",
      "y test shape: (250, 31, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"x train shape: {X_train.shape}\")\n",
    "print(f\"y train shape: {y_train.shape}\")\n",
    "print(f\"x test shape: {X_test.shape}\")\n",
    "print(f\"y test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T16:22:49.629866Z",
     "start_time": "2019-03-05T16:19:35.734536Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18352 samples, validate on 4588 samples\n",
      "Epoch 1/1000\n",
      "18352/18352 [==============================] - 2s 112us/step - loss: 0.6928 - acc: 0.5134 - val_loss: 0.6932 - val_acc: 0.5153\n",
      "Epoch 2/1000\n",
      "18352/18352 [==============================] - 2s 84us/step - loss: 0.6927 - acc: 0.5154 - val_loss: 0.6927 - val_acc: 0.5129\n",
      "Epoch 3/1000\n",
      "18352/18352 [==============================] - 2s 82us/step - loss: 0.6926 - acc: 0.5166 - val_loss: 0.6928 - val_acc: 0.5163\n",
      "Epoch 4/1000\n",
      "18352/18352 [==============================] - 2s 83us/step - loss: 0.6925 - acc: 0.5181 - val_loss: 0.6929 - val_acc: 0.5126\n",
      "Epoch 5/1000\n",
      "18352/18352 [==============================] - 2s 84us/step - loss: 0.6926 - acc: 0.5172 - val_loss: 0.6929 - val_acc: 0.5102\n",
      "Epoch 6/1000\n",
      "18352/18352 [==============================] - 2s 84us/step - loss: 0.6926 - acc: 0.5155 - val_loss: 0.6929 - val_acc: 0.5133\n",
      "Epoch 7/1000\n",
      "18352/18352 [==============================] - 2s 83us/step - loss: 0.6924 - acc: 0.5145 - val_loss: 0.6928 - val_acc: 0.5087\n",
      "Epoch 8/1000\n",
      "18352/18352 [==============================] - 2s 83us/step - loss: 0.6924 - acc: 0.5171 - val_loss: 0.6926 - val_acc: 0.5172\n",
      "Epoch 9/1000\n",
      "18352/18352 [==============================] - 2s 85us/step - loss: 0.6925 - acc: 0.5168 - val_loss: 0.6928 - val_acc: 0.5146\n",
      "Epoch 10/1000\n",
      "18352/18352 [==============================] - 2s 84us/step - loss: 0.6924 - acc: 0.5183 - val_loss: 0.6929 - val_acc: 0.5163\n",
      "Epoch 11/1000\n",
      "18352/18352 [==============================] - 2s 85us/step - loss: 0.6925 - acc: 0.5190 - val_loss: 0.6930 - val_acc: 0.5183\n",
      "Epoch 12/1000\n",
      "18352/18352 [==============================] - 2s 83us/step - loss: 0.6924 - acc: 0.5191 - val_loss: 0.6931 - val_acc: 0.5174\n",
      "Epoch 13/1000\n",
      "18352/18352 [==============================] - 2s 86us/step - loss: 0.6924 - acc: 0.5199 - val_loss: 0.6928 - val_acc: 0.5157\n",
      "Epoch 14/1000\n",
      "18352/18352 [==============================] - 2s 84us/step - loss: 0.6924 - acc: 0.5155 - val_loss: 0.6929 - val_acc: 0.5172\n",
      "Epoch 15/1000\n",
      "18352/18352 [==============================] - 2s 88us/step - loss: 0.6924 - acc: 0.5191 - val_loss: 0.6930 - val_acc: 0.5183\n",
      "Epoch 16/1000\n",
      "18352/18352 [==============================] - 2s 85us/step - loss: 0.6924 - acc: 0.5188 - val_loss: 0.6931 - val_acc: 0.5085\n",
      "Epoch 17/1000\n",
      "18352/18352 [==============================] - 2s 86us/step - loss: 0.6924 - acc: 0.5169 - val_loss: 0.6927 - val_acc: 0.5187\n",
      "Epoch 18/1000\n",
      "18352/18352 [==============================] - 2s 85us/step - loss: 0.6924 - acc: 0.5189 - val_loss: 0.6926 - val_acc: 0.5233\n",
      "Epoch 19/1000\n",
      "18352/18352 [==============================] - 1s 81us/step - loss: 0.6923 - acc: 0.5208 - val_loss: 0.6930 - val_acc: 0.5185\n",
      "Epoch 20/1000\n",
      "18352/18352 [==============================] - 2s 90us/step - loss: 0.6921 - acc: 0.5193 - val_loss: 0.6933 - val_acc: 0.5120\n",
      "Epoch 21/1000\n",
      "18352/18352 [==============================] - 2s 88us/step - loss: 0.6922 - acc: 0.5203 - val_loss: 0.6933 - val_acc: 0.5139\n",
      "Epoch 22/1000\n",
      "18352/18352 [==============================] - 2s 93us/step - loss: 0.6924 - acc: 0.5165 - val_loss: 0.6933 - val_acc: 0.5124\n",
      "Epoch 23/1000\n",
      "18352/18352 [==============================] - 2s 100us/step - loss: 0.6922 - acc: 0.5172 - val_loss: 0.6934 - val_acc: 0.5107\n",
      "Epoch 24/1000\n",
      "18352/18352 [==============================] - 2s 94us/step - loss: 0.6921 - acc: 0.5196 - val_loss: 0.6936 - val_acc: 0.5100\n",
      "Epoch 25/1000\n",
      "18352/18352 [==============================] - 2s 91us/step - loss: 0.6925 - acc: 0.5168 - val_loss: 0.6933 - val_acc: 0.5150\n",
      "Epoch 26/1000\n",
      "18352/18352 [==============================] - 2s 87us/step - loss: 0.6922 - acc: 0.5164 - val_loss: 0.6935 - val_acc: 0.5113\n",
      "Epoch 27/1000\n",
      "18352/18352 [==============================] - 2s 90us/step - loss: 0.6923 - acc: 0.5202 - val_loss: 0.6933 - val_acc: 0.5109\n",
      "Epoch 28/1000\n",
      "18352/18352 [==============================] - 2s 88us/step - loss: 0.6922 - acc: 0.5173 - val_loss: 0.6931 - val_acc: 0.5192\n",
      "Epoch 29/1000\n",
      "18352/18352 [==============================] - 2s 86us/step - loss: 0.6924 - acc: 0.5155 - val_loss: 0.6935 - val_acc: 0.5096\n",
      "Epoch 30/1000\n",
      "18352/18352 [==============================] - 2s 88us/step - loss: 0.6921 - acc: 0.5216 - val_loss: 0.6934 - val_acc: 0.5120\n",
      "Epoch 31/1000\n",
      "18352/18352 [==============================] - 2s 101us/step - loss: 0.6922 - acc: 0.5184 - val_loss: 0.6937 - val_acc: 0.5131\n",
      "Epoch 32/1000\n",
      "18352/18352 [==============================] - 2s 104us/step - loss: 0.6921 - acc: 0.5186 - val_loss: 0.6935 - val_acc: 0.5124\n",
      "Epoch 33/1000\n",
      "18352/18352 [==============================] - 2s 86us/step - loss: 0.6921 - acc: 0.5201 - val_loss: 0.6934 - val_acc: 0.5109\n",
      "Epoch 34/1000\n",
      "18352/18352 [==============================] - 2s 86us/step - loss: 0.6918 - acc: 0.5216 - val_loss: 0.6937 - val_acc: 0.5135\n",
      "Epoch 35/1000\n",
      "18352/18352 [==============================] - 2s 84us/step - loss: 0.6919 - acc: 0.5208 - val_loss: 0.6938 - val_acc: 0.5116\n",
      "Epoch 36/1000\n",
      "18352/18352 [==============================] - 2s 87us/step - loss: 0.6919 - acc: 0.5216 - val_loss: 0.6937 - val_acc: 0.5146\n",
      "Epoch 37/1000\n",
      "18352/18352 [==============================] - 2s 88us/step - loss: 0.6918 - acc: 0.5212 - val_loss: 0.6938 - val_acc: 0.5129\n",
      "Epoch 38/1000\n",
      "18352/18352 [==============================] - 2s 89us/step - loss: 0.6920 - acc: 0.5198 - val_loss: 0.6934 - val_acc: 0.5139\n",
      "Epoch 39/1000\n",
      "18352/18352 [==============================] - 2s 94us/step - loss: 0.6919 - acc: 0.5215 - val_loss: 0.6938 - val_acc: 0.5089\n",
      "Epoch 40/1000\n",
      "18352/18352 [==============================] - 2s 110us/step - loss: 0.6919 - acc: 0.5196 - val_loss: 0.6939 - val_acc: 0.5170\n",
      "Epoch 41/1000\n",
      "18352/18352 [==============================] - 2s 104us/step - loss: 0.6916 - acc: 0.5213 - val_loss: 0.6942 - val_acc: 0.5124\n",
      "Epoch 42/1000\n",
      "18352/18352 [==============================] - 2s 108us/step - loss: 0.6917 - acc: 0.5212 - val_loss: 0.6939 - val_acc: 0.5098\n",
      "Epoch 43/1000\n",
      "18352/18352 [==============================] - 2s 101us/step - loss: 0.6917 - acc: 0.5231 - val_loss: 0.6938 - val_acc: 0.5081\n",
      "Epoch 44/1000\n",
      "18352/18352 [==============================] - 2s 91us/step - loss: 0.6919 - acc: 0.5176 - val_loss: 0.6938 - val_acc: 0.5146\n",
      "Epoch 45/1000\n",
      "18352/18352 [==============================] - 2s 102us/step - loss: 0.6916 - acc: 0.5248 - val_loss: 0.6940 - val_acc: 0.5102\n",
      "Epoch 46/1000\n",
      "18352/18352 [==============================] - 2s 95us/step - loss: 0.6916 - acc: 0.5226 - val_loss: 0.6943 - val_acc: 0.5139\n",
      "Epoch 47/1000\n",
      "18352/18352 [==============================] - 2s 91us/step - loss: 0.6920 - acc: 0.5202 - val_loss: 0.6939 - val_acc: 0.5155\n",
      "Epoch 48/1000\n",
      "18352/18352 [==============================] - 2s 97us/step - loss: 0.6916 - acc: 0.5201 - val_loss: 0.6937 - val_acc: 0.5174\n",
      "Epoch 49/1000\n",
      "18352/18352 [==============================] - 2s 96us/step - loss: 0.6914 - acc: 0.5235 - val_loss: 0.6947 - val_acc: 0.4993\n",
      "Epoch 50/1000\n",
      "18352/18352 [==============================] - 2s 89us/step - loss: 0.6917 - acc: 0.5187 - val_loss: 0.6941 - val_acc: 0.5118\n",
      "Epoch 51/1000\n",
      "18352/18352 [==============================] - 2s 95us/step - loss: 0.6913 - acc: 0.5232 - val_loss: 0.6936 - val_acc: 0.5177\n",
      "Epoch 52/1000\n",
      "18352/18352 [==============================] - 2s 109us/step - loss: 0.6915 - acc: 0.5246 - val_loss: 0.6944 - val_acc: 0.5163\n",
      "Epoch 53/1000\n",
      "18352/18352 [==============================] - 2s 104us/step - loss: 0.6918 - acc: 0.5226 - val_loss: 0.6940 - val_acc: 0.5107\n",
      "Epoch 54/1000\n",
      "18352/18352 [==============================] - 2s 101us/step - loss: 0.6915 - acc: 0.5222 - val_loss: 0.6941 - val_acc: 0.5126\n",
      "Epoch 55/1000\n",
      "18352/18352 [==============================] - 2s 96us/step - loss: 0.6913 - acc: 0.5183 - val_loss: 0.6944 - val_acc: 0.5163\n",
      "Epoch 56/1000\n",
      "18352/18352 [==============================] - 2s 92us/step - loss: 0.6916 - acc: 0.5221 - val_loss: 0.6942 - val_acc: 0.5118\n",
      "Epoch 57/1000\n",
      "18352/18352 [==============================] - 2s 91us/step - loss: 0.6912 - acc: 0.5278 - val_loss: 0.6949 - val_acc: 0.5133\n",
      "Epoch 58/1000\n",
      "18352/18352 [==============================] - 2s 88us/step - loss: 0.6914 - acc: 0.5230 - val_loss: 0.6940 - val_acc: 0.5044\n",
      "Epoch 59/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18352/18352 [==============================] - 2s 91us/step - loss: 0.6914 - acc: 0.5227 - val_loss: 0.6943 - val_acc: 0.5146\n",
      "Epoch 60/1000\n",
      "18352/18352 [==============================] - 2s 87us/step - loss: 0.6914 - acc: 0.5237 - val_loss: 0.6946 - val_acc: 0.5007\n",
      "Epoch 61/1000\n",
      "18352/18352 [==============================] - 2s 88us/step - loss: 0.6911 - acc: 0.5266 - val_loss: 0.6945 - val_acc: 0.5122\n",
      "Epoch 62/1000\n",
      "18352/18352 [==============================] - 2s 96us/step - loss: 0.6914 - acc: 0.5227 - val_loss: 0.6942 - val_acc: 0.5161\n",
      "Epoch 63/1000\n",
      "18352/18352 [==============================] - 2s 88us/step - loss: 0.6912 - acc: 0.5247 - val_loss: 0.6951 - val_acc: 0.5163\n",
      "Epoch 64/1000\n",
      "18352/18352 [==============================] - 2s 90us/step - loss: 0.6914 - acc: 0.5218 - val_loss: 0.6945 - val_acc: 0.5133\n",
      "Epoch 65/1000\n",
      "18352/18352 [==============================] - 2s 89us/step - loss: 0.6912 - acc: 0.5237 - val_loss: 0.6947 - val_acc: 0.5133\n",
      "Epoch 66/1000\n",
      "18352/18352 [==============================] - 2s 93us/step - loss: 0.6913 - acc: 0.5235 - val_loss: 0.6943 - val_acc: 0.5144\n",
      "Epoch 67/1000\n",
      "18352/18352 [==============================] - 2s 97us/step - loss: 0.6913 - acc: 0.5209 - val_loss: 0.6941 - val_acc: 0.5105\n",
      "Epoch 68/1000\n",
      "18352/18352 [==============================] - 2s 92us/step - loss: 0.6910 - acc: 0.5241 - val_loss: 0.6949 - val_acc: 0.5094\n",
      "Epoch 69/1000\n",
      "18352/18352 [==============================] - 2s 92us/step - loss: 0.6911 - acc: 0.5263 - val_loss: 0.6945 - val_acc: 0.5085\n",
      "Epoch 70/1000\n",
      "18352/18352 [==============================] - 2s 87us/step - loss: 0.6908 - acc: 0.5270 - val_loss: 0.6947 - val_acc: 0.5061\n",
      "Epoch 71/1000\n",
      "18352/18352 [==============================] - 2s 86us/step - loss: 0.6914 - acc: 0.5250 - val_loss: 0.6944 - val_acc: 0.5111\n",
      "Epoch 72/1000\n",
      "18352/18352 [==============================] - 2s 87us/step - loss: 0.6912 - acc: 0.5267 - val_loss: 0.6950 - val_acc: 0.5083\n",
      "Epoch 73/1000\n",
      "18352/18352 [==============================] - 2s 85us/step - loss: 0.6908 - acc: 0.5251 - val_loss: 0.6947 - val_acc: 0.5137\n",
      "Epoch 74/1000\n",
      "18352/18352 [==============================] - 2s 84us/step - loss: 0.6911 - acc: 0.5263 - val_loss: 0.6954 - val_acc: 0.5129\n",
      "Epoch 75/1000\n",
      "18352/18352 [==============================] - 2s 83us/step - loss: 0.6910 - acc: 0.5242 - val_loss: 0.6952 - val_acc: 0.5124\n",
      "Epoch 76/1000\n",
      "18352/18352 [==============================] - 2s 84us/step - loss: 0.6910 - acc: 0.5273 - val_loss: 0.6946 - val_acc: 0.5076\n",
      "Epoch 77/1000\n",
      "18352/18352 [==============================] - 2s 85us/step - loss: 0.6909 - acc: 0.5257 - val_loss: 0.6943 - val_acc: 0.5065\n",
      "Epoch 78/1000\n",
      "18352/18352 [==============================] - 2s 84us/step - loss: 0.6907 - acc: 0.5262 - val_loss: 0.6954 - val_acc: 0.5116\n",
      "Epoch 79/1000\n",
      "18352/18352 [==============================] - 2s 84us/step - loss: 0.6908 - acc: 0.5263 - val_loss: 0.6944 - val_acc: 0.5122\n",
      "Epoch 80/1000\n",
      "18352/18352 [==============================] - 2s 88us/step - loss: 0.6908 - acc: 0.5251 - val_loss: 0.6954 - val_acc: 0.5105\n",
      "Epoch 81/1000\n",
      "18352/18352 [==============================] - 2s 87us/step - loss: 0.6908 - acc: 0.5268 - val_loss: 0.6952 - val_acc: 0.5031\n",
      "Epoch 82/1000\n",
      "18352/18352 [==============================] - 2s 85us/step - loss: 0.6902 - acc: 0.5296 - val_loss: 0.6956 - val_acc: 0.5116\n",
      "Epoch 83/1000\n",
      "18352/18352 [==============================] - 2s 84us/step - loss: 0.6908 - acc: 0.5248 - val_loss: 0.6950 - val_acc: 0.5044\n",
      "Epoch 84/1000\n",
      "18352/18352 [==============================] - 2s 84us/step - loss: 0.6904 - acc: 0.5261 - val_loss: 0.6954 - val_acc: 0.5031\n",
      "Epoch 85/1000\n",
      "18352/18352 [==============================] - 2s 90us/step - loss: 0.6906 - acc: 0.5231 - val_loss: 0.6946 - val_acc: 0.5022\n",
      "Epoch 86/1000\n",
      "18352/18352 [==============================] - 2s 87us/step - loss: 0.6909 - acc: 0.5266 - val_loss: 0.6946 - val_acc: 0.5065\n",
      "Epoch 87/1000\n",
      "18352/18352 [==============================] - 2s 83us/step - loss: 0.6906 - acc: 0.5264 - val_loss: 0.6946 - val_acc: 0.5109\n",
      "Epoch 88/1000\n",
      "18352/18352 [==============================] - 2s 85us/step - loss: 0.6905 - acc: 0.5265 - val_loss: 0.6949 - val_acc: 0.5020\n",
      "Epoch 89/1000\n",
      "18352/18352 [==============================] - 2s 86us/step - loss: 0.6906 - acc: 0.5277 - val_loss: 0.6951 - val_acc: 0.5085\n",
      "Epoch 90/1000\n",
      "18352/18352 [==============================] - 2s 86us/step - loss: 0.6909 - acc: 0.5276 - val_loss: 0.6946 - val_acc: 0.5063\n",
      "Epoch 91/1000\n",
      "18352/18352 [==============================] - 2s 87us/step - loss: 0.6906 - acc: 0.5264 - val_loss: 0.6953 - val_acc: 0.5072\n",
      "Epoch 92/1000\n",
      "18352/18352 [==============================] - 2s 83us/step - loss: 0.6901 - acc: 0.5290 - val_loss: 0.6954 - val_acc: 0.5102\n",
      "Epoch 93/1000\n",
      "18352/18352 [==============================] - 2s 84us/step - loss: 0.6904 - acc: 0.5248 - val_loss: 0.6958 - val_acc: 0.5081\n",
      "Epoch 94/1000\n",
      "18352/18352 [==============================] - 2s 90us/step - loss: 0.6905 - acc: 0.5265 - val_loss: 0.6956 - val_acc: 0.5026\n",
      "Epoch 95/1000\n",
      "18352/18352 [==============================] - 2s 86us/step - loss: 0.6901 - acc: 0.5260 - val_loss: 0.6943 - val_acc: 0.4972\n",
      "Epoch 96/1000\n",
      "18352/18352 [==============================] - 2s 101us/step - loss: 0.6902 - acc: 0.5250 - val_loss: 0.6951 - val_acc: 0.5022\n",
      "Epoch 97/1000\n",
      "18352/18352 [==============================] - 2s 91us/step - loss: 0.6901 - acc: 0.5264 - val_loss: 0.6948 - val_acc: 0.5083\n",
      "Epoch 98/1000\n",
      "18352/18352 [==============================] - 2s 84us/step - loss: 0.6901 - acc: 0.5269 - val_loss: 0.6955 - val_acc: 0.5085\n",
      "Epoch 99/1000\n",
      "18352/18352 [==============================] - 2s 84us/step - loss: 0.6900 - acc: 0.5248 - val_loss: 0.6950 - val_acc: 0.5024\n",
      "Epoch 100/1000\n",
      "18352/18352 [==============================] - 2s 85us/step - loss: 0.6898 - acc: 0.5282 - val_loss: 0.6964 - val_acc: 0.5057\n",
      "Epoch 101/1000\n",
      "18352/18352 [==============================] - 2s 91us/step - loss: 0.6899 - acc: 0.5263 - val_loss: 0.6961 - val_acc: 0.5048\n",
      "Epoch 102/1000\n",
      "18352/18352 [==============================] - 2s 84us/step - loss: 0.6900 - acc: 0.5240 - val_loss: 0.6967 - val_acc: 0.5022\n",
      "Epoch 103/1000\n",
      "18352/18352 [==============================] - 2s 82us/step - loss: 0.6894 - acc: 0.5286 - val_loss: 0.6963 - val_acc: 0.5044\n",
      "Epoch 104/1000\n",
      "18352/18352 [==============================] - 2s 83us/step - loss: 0.6896 - acc: 0.5282 - val_loss: 0.6957 - val_acc: 0.5048\n",
      "Epoch 105/1000\n",
      "18352/18352 [==============================] - 2s 83us/step - loss: 0.6896 - acc: 0.5277 - val_loss: 0.6955 - val_acc: 0.5102\n",
      "Epoch 106/1000\n",
      "18352/18352 [==============================] - 2s 83us/step - loss: 0.6893 - acc: 0.5284 - val_loss: 0.6957 - val_acc: 0.5048\n",
      "Epoch 107/1000\n",
      "18352/18352 [==============================] - 2s 90us/step - loss: 0.6897 - acc: 0.5252 - val_loss: 0.6954 - val_acc: 0.5002\n",
      "Epoch 108/1000\n",
      "18352/18352 [==============================] - 2s 84us/step - loss: 0.6891 - acc: 0.5293 - val_loss: 0.6968 - val_acc: 0.5122\n",
      "Epoch 109/1000\n",
      "18352/18352 [==============================] - 2s 86us/step - loss: 0.6894 - acc: 0.5255 - val_loss: 0.6956 - val_acc: 0.5046\n",
      "Epoch 110/1000\n",
      "18352/18352 [==============================] - 2s 86us/step - loss: 0.6890 - acc: 0.5291 - val_loss: 0.6965 - val_acc: 0.5044\n",
      "Epoch 111/1000\n",
      "18352/18352 [==============================] - 2s 83us/step - loss: 0.6891 - acc: 0.5310 - val_loss: 0.6963 - val_acc: 0.5074\n",
      "Epoch 112/1000\n",
      "18352/18352 [==============================] - 2s 88us/step - loss: 0.6890 - acc: 0.5292 - val_loss: 0.6966 - val_acc: 0.5074\n",
      "Epoch 113/1000\n",
      "18352/18352 [==============================] - 2s 92us/step - loss: 0.6890 - acc: 0.5286 - val_loss: 0.6968 - val_acc: 0.5061\n",
      "Epoch 114/1000\n",
      "18352/18352 [==============================] - 2s 85us/step - loss: 0.6889 - acc: 0.5287 - val_loss: 0.6966 - val_acc: 0.5150\n",
      "Epoch 115/1000\n",
      "18352/18352 [==============================] - 2s 83us/step - loss: 0.6888 - acc: 0.5299 - val_loss: 0.6963 - val_acc: 0.5065\n",
      "Epoch 116/1000\n",
      "18352/18352 [==============================] - 2s 85us/step - loss: 0.6890 - acc: 0.5293 - val_loss: 0.6963 - val_acc: 0.5057\n",
      "Epoch 117/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18352/18352 [==============================] - 2s 87us/step - loss: 0.6887 - acc: 0.5272 - val_loss: 0.6966 - val_acc: 0.5085\n",
      "Epoch 118/1000\n",
      "18352/18352 [==============================] - 2s 83us/step - loss: 0.6892 - acc: 0.5269 - val_loss: 0.6958 - val_acc: 0.5078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9688321208>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "\n",
    "# The LSTM architecture\n",
    "regressor = Sequential()\n",
    "# regressor.add(LSTM(units=25, return_sequences=True, input_shape=(240, 31)))\n",
    "regressor.add(LSTM(units=25, input_shape=(timestep, 1), dropout=0.1))\n",
    "\n",
    "\n",
    "# regressor.add(LSTM(units = 10, input_shape = (X_train.shape[1], 1)))\n",
    "# regressor.add(Dropout(0.2))\n",
    "\n",
    "# regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "# regressor.add(Dropout(0.2))\n",
    "\n",
    "# regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "# regressor.add(Dropout(0.2))\n",
    "\n",
    "# regressor.add(LSTM(units = 10))\n",
    "# regressor.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "regressor.add(Dense(2, activation='softmax'))\n",
    "\n",
    "regressor.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "# regressor.compile(loss='mean_squared_error',\n",
    "#               optimizer='rmsprop',\n",
    "#               metrics=['accuracy'])\n",
    "# Fitting to the training set\n",
    "regressor.fit(X_train,y_train,epochs=1000,batch_size=128, validation_split=0.2, callbacks = [EarlyStopping(monitor='val_loss', mode='min', patience=100),\n",
    "             ModelCheckpoint(filepath='../model/LSTM/best_model.h5', monitor='val_acc', save_best_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T16:18:37.709347Z",
     "start_time": "2019-03-05T16:18:34.216Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluating our model\n",
    "predicted = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T16:18:37.710241Z",
     "start_time": "2019-03-05T16:18:34.217Z"
    }
   },
   "outputs": [],
   "source": [
    "label = predicted > 0.5\n",
    "label = label * 1 # Convert boolean to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T16:18:37.710985Z",
     "start_time": "2019-03-05T16:18:34.219Z"
    }
   },
   "outputs": [],
   "source": [
    "(sum(y_test[:, :, 1] == label[:, :, 1])/(y_test.size/2)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T16:18:37.711706Z",
     "start_time": "2019-03-05T16:18:34.221Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = '../model/LSTM/my_model3.h5'\n",
    "regressor.save(model_name)  # creates a HDF5 file 'my_model.h5'\n",
    "del regressor  # deletes the existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T16:18:37.712427Z",
     "start_time": "2019-03-05T16:18:34.222Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.activations import softmax\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "regressor1 = load_model(model_name, custom_objects={\"softmax\": softmax})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-05T16:18:37.713254Z",
     "start_time": "2019-03-05T16:18:34.224Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted_load = regressor1.predict(X_test)\n",
    "label_load = predicted_load > 0.5\n",
    "label_load = label_load * 1 # Convert boolean to int\n",
    "(sum(y_test[:, :, 1] == label_load[:, :, 1])/(y_test.size/2)).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet_S5",
   "language": "python",
   "name": "projet_s5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
