{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T11:34:37.690671Z",
     "start_time": "2019-03-04T11:34:36.894981Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List all device\n",
    "from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T11:34:37.728189Z",
     "start_time": "2019-03-04T11:34:37.692119Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check available GPU\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T11:34:37.781582Z",
     "start_time": "2019-03-04T11:34:37.729565Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "# The GPU id to use, usually either \"0\" or \"1\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T11:34:37.861730Z",
     "start_time": "2019-03-04T11:34:37.789395Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Reshape, Lambda\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.activations import softmax\n",
    "from keras.optimizers import SGD\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T11:34:37.950814Z",
     "start_time": "2019-03-04T11:34:37.869052Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"../data/dowjones_calculated/periods.txt\", \"rb\") as fp:   # Unpickling\n",
    "    dataset = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T11:34:39.049319Z",
     "start_time": "2019-03-04T11:34:37.953128Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = dataset[0][0][0].values\n",
    "y_train = dataset[0][0][1].values\n",
    "X_test = dataset[1][0][0].values\n",
    "y_test = dataset[1][0][1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T11:34:39.187048Z",
     "start_time": "2019-03-04T11:34:39.054415Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_one_hot(targets, nb_classes):\n",
    "    res = np.eye(nb_classes)[np.array(targets).reshape(-1)]\n",
    "    return res.reshape(list(targets.shape)+[nb_classes])\n",
    "y_train = get_one_hot(y_train, 2)\n",
    "y_test = get_one_hot(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T11:34:39.266908Z",
     "start_time": "2019-03-04T11:34:39.192401Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train shape: (750, 31)\n",
      "y train shape: (750, 31, 2)\n",
      "x test shape: (250, 31)\n",
      "y test shape: (250, 31, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"x train shape: {X_train.shape}\")\n",
    "print(f\"y train shape: {y_train.shape}\")\n",
    "print(f\"x test shape: {X_test.shape}\")\n",
    "print(f\"y test shape: {y_test.shape}\")\n",
    "# print(f\"predicted shape: {predicted.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T11:34:39.341545Z",
     "start_time": "2019-03-04T11:34:39.271356Z"
    }
   },
   "outputs": [],
   "source": [
    "data = X_train\n",
    "targets = y_train\n",
    "\n",
    "train_gen = TimeseriesGenerator(data, targets,\n",
    "                               length=240, sampling_rate=1,\n",
    "                               batch_size=510)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T11:34:39.450891Z",
     "start_time": "2019-03-04T11:34:39.343879Z"
    }
   },
   "outputs": [],
   "source": [
    "data = X_test\n",
    "targets = y_test\n",
    "\n",
    "test_gen = TimeseriesGenerator(data, targets,\n",
    "                               length=240, sampling_rate=1,\n",
    "                               batch_size=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T11:34:39.613675Z",
     "start_time": "2019-03-04T11:34:39.455282Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = train_gen[0][0]\n",
    "y_train = train_gen[0][1]\n",
    "X_test = test_gen[0][0]\n",
    "y_test = test_gen[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T11:34:39.617044Z",
     "start_time": "2019-03-04T11:34:39.614858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train shape: (510, 240, 31)\n",
      "y train shape: (510, 31, 2)\n",
      "x test shape: (10, 240, 31)\n",
      "y test shape: (10, 31, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"x train shape: {X_train.shape}\")\n",
    "print(f\"y train shape: {y_train.shape}\")\n",
    "print(f\"x test shape: {X_test.shape}\")\n",
    "print(f\"y test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T11:34:39.698263Z",
     "start_time": "2019-03-04T11:34:39.618316Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reshaping X_train for efficient modelling\n",
    "# X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
    "# X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], X_test.shape[2], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T11:34:39.783224Z",
     "start_time": "2019-03-04T11:34:39.700473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train shape: (510, 240, 31)\n",
      "y train shape: (510, 31, 2)\n",
      "x test shape: (10, 240, 31)\n",
      "y test shape: (10, 31, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"x train shape: {X_train.shape}\")\n",
    "print(f\"y train shape: {y_train.shape}\")\n",
    "print(f\"x test shape: {X_test.shape}\")\n",
    "print(f\"y test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T11:41:00.471586Z",
     "start_time": "2019-03-04T11:34:39.788845Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 459 samples, validate on 51 samples\n",
      "Epoch 1/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2506 - acc: 0.4893 - val_loss: 0.2521 - val_acc: 0.4719\n",
      "Epoch 2/100\n",
      "459/459 [==============================] - 4s 8ms/step - loss: 0.2500 - acc: 0.5019 - val_loss: 0.2520 - val_acc: 0.4756\n",
      "Epoch 3/100\n",
      "459/459 [==============================] - 4s 8ms/step - loss: 0.2494 - acc: 0.5085 - val_loss: 0.2519 - val_acc: 0.4756\n",
      "Epoch 4/100\n",
      "459/459 [==============================] - 4s 8ms/step - loss: 0.2492 - acc: 0.5104 - val_loss: 0.2520 - val_acc: 0.4738\n",
      "Epoch 5/100\n",
      "459/459 [==============================] - 4s 8ms/step - loss: 0.2489 - acc: 0.5137 - val_loss: 0.2520 - val_acc: 0.4756\n",
      "Epoch 6/100\n",
      "459/459 [==============================] - 4s 8ms/step - loss: 0.2486 - acc: 0.5182 - val_loss: 0.2521 - val_acc: 0.4756\n",
      "Epoch 7/100\n",
      "459/459 [==============================] - 4s 8ms/step - loss: 0.2483 - acc: 0.5224 - val_loss: 0.2519 - val_acc: 0.4832\n",
      "Epoch 8/100\n",
      "459/459 [==============================] - 4s 8ms/step - loss: 0.2480 - acc: 0.5304 - val_loss: 0.2521 - val_acc: 0.4769\n",
      "Epoch 9/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2478 - acc: 0.5300 - val_loss: 0.2521 - val_acc: 0.4775\n",
      "Epoch 10/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2475 - acc: 0.5315 - val_loss: 0.2522 - val_acc: 0.4794\n",
      "Epoch 11/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2472 - acc: 0.5325 - val_loss: 0.2524 - val_acc: 0.4864\n",
      "Epoch 12/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2469 - acc: 0.5383 - val_loss: 0.2523 - val_acc: 0.4915\n",
      "Epoch 13/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2465 - acc: 0.5385 - val_loss: 0.2525 - val_acc: 0.4908\n",
      "Epoch 14/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2462 - acc: 0.5455 - val_loss: 0.2525 - val_acc: 0.4965\n",
      "Epoch 15/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2463 - acc: 0.5407 - val_loss: 0.2524 - val_acc: 0.4953\n",
      "Epoch 16/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2458 - acc: 0.5478 - val_loss: 0.2527 - val_acc: 0.4965\n",
      "Epoch 17/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2453 - acc: 0.5494 - val_loss: 0.2531 - val_acc: 0.4934\n",
      "Epoch 18/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2448 - acc: 0.5513 - val_loss: 0.2534 - val_acc: 0.4946\n",
      "Epoch 19/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2448 - acc: 0.5494 - val_loss: 0.2535 - val_acc: 0.4965\n",
      "Epoch 20/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2449 - acc: 0.5506 - val_loss: 0.2536 - val_acc: 0.4953\n",
      "Epoch 21/100\n",
      "459/459 [==============================] - 4s 10ms/step - loss: 0.2442 - acc: 0.5551 - val_loss: 0.2539 - val_acc: 0.4927\n",
      "Epoch 22/100\n",
      "459/459 [==============================] - 4s 10ms/step - loss: 0.2437 - acc: 0.5586 - val_loss: 0.2543 - val_acc: 0.4946\n",
      "Epoch 23/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2438 - acc: 0.5531 - val_loss: 0.2542 - val_acc: 0.4972\n",
      "Epoch 24/100\n",
      "459/459 [==============================] - 4s 10ms/step - loss: 0.2434 - acc: 0.5585 - val_loss: 0.2543 - val_acc: 0.4984\n",
      "Epoch 25/100\n",
      "459/459 [==============================] - 4s 10ms/step - loss: 0.2434 - acc: 0.5611 - val_loss: 0.2545 - val_acc: 0.4978\n",
      "Epoch 26/100\n",
      "459/459 [==============================] - 4s 10ms/step - loss: 0.2428 - acc: 0.5603 - val_loss: 0.2548 - val_acc: 0.4972\n",
      "Epoch 27/100\n",
      "459/459 [==============================] - 4s 10ms/step - loss: 0.2425 - acc: 0.5633 - val_loss: 0.2548 - val_acc: 0.5016\n",
      "Epoch 28/100\n",
      "459/459 [==============================] - 5s 10ms/step - loss: 0.2421 - acc: 0.5617 - val_loss: 0.2549 - val_acc: 0.4984\n",
      "Epoch 29/100\n",
      "459/459 [==============================] - 4s 10ms/step - loss: 0.2421 - acc: 0.5641 - val_loss: 0.2549 - val_acc: 0.4978\n",
      "Epoch 30/100\n",
      "459/459 [==============================] - 5s 10ms/step - loss: 0.2415 - acc: 0.5647 - val_loss: 0.2552 - val_acc: 0.4991\n",
      "Epoch 31/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2414 - acc: 0.5671 - val_loss: 0.2556 - val_acc: 0.5016\n",
      "Epoch 32/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2414 - acc: 0.5646 - val_loss: 0.2561 - val_acc: 0.5035\n",
      "Epoch 33/100\n",
      "459/459 [==============================] - 5s 11ms/step - loss: 0.2406 - acc: 0.5703 - val_loss: 0.2562 - val_acc: 0.5003\n",
      "Epoch 34/100\n",
      "459/459 [==============================] - 5s 10ms/step - loss: 0.2405 - acc: 0.5709 - val_loss: 0.2563 - val_acc: 0.5009\n",
      "Epoch 35/100\n",
      "459/459 [==============================] - 4s 10ms/step - loss: 0.2402 - acc: 0.5729 - val_loss: 0.2566 - val_acc: 0.5009\n",
      "Epoch 36/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2401 - acc: 0.5712 - val_loss: 0.2567 - val_acc: 0.4889\n",
      "Epoch 37/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2395 - acc: 0.5747 - val_loss: 0.2568 - val_acc: 0.4921\n",
      "Epoch 38/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2395 - acc: 0.5771 - val_loss: 0.2571 - val_acc: 0.4940\n",
      "Epoch 39/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2390 - acc: 0.5766 - val_loss: 0.2571 - val_acc: 0.5054\n",
      "Epoch 40/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2391 - acc: 0.5787 - val_loss: 0.2574 - val_acc: 0.4991\n",
      "Epoch 41/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2381 - acc: 0.5796 - val_loss: 0.2582 - val_acc: 0.4883\n",
      "Epoch 42/100\n",
      "459/459 [==============================] - 4s 10ms/step - loss: 0.2384 - acc: 0.5781 - val_loss: 0.2582 - val_acc: 0.4870\n",
      "Epoch 43/100\n",
      "459/459 [==============================] - 4s 10ms/step - loss: 0.2382 - acc: 0.5780 - val_loss: 0.2582 - val_acc: 0.4896\n",
      "Epoch 44/100\n",
      "459/459 [==============================] - 5s 10ms/step - loss: 0.2380 - acc: 0.5759 - val_loss: 0.2581 - val_acc: 0.4864\n",
      "Epoch 45/100\n",
      "459/459 [==============================] - 4s 10ms/step - loss: 0.2376 - acc: 0.5835 - val_loss: 0.2586 - val_acc: 0.4813\n",
      "Epoch 46/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2374 - acc: 0.5837 - val_loss: 0.2588 - val_acc: 0.4864\n",
      "Epoch 47/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2374 - acc: 0.5837 - val_loss: 0.2589 - val_acc: 0.4858\n",
      "Epoch 48/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2367 - acc: 0.5835 - val_loss: 0.2592 - val_acc: 0.4877\n",
      "Epoch 49/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2363 - acc: 0.5865 - val_loss: 0.2593 - val_acc: 0.4896\n",
      "Epoch 50/100\n",
      "459/459 [==============================] - 4s 10ms/step - loss: 0.2363 - acc: 0.5870 - val_loss: 0.2598 - val_acc: 0.4889\n",
      "Epoch 51/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2363 - acc: 0.5828 - val_loss: 0.2595 - val_acc: 0.4870\n",
      "Epoch 52/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2352 - acc: 0.5898 - val_loss: 0.2597 - val_acc: 0.4839\n",
      "Epoch 53/100\n",
      "459/459 [==============================] - 4s 10ms/step - loss: 0.2350 - acc: 0.5905 - val_loss: 0.2601 - val_acc: 0.4839\n",
      "Epoch 54/100\n",
      "459/459 [==============================] - 4s 10ms/step - loss: 0.2354 - acc: 0.5903 - val_loss: 0.2597 - val_acc: 0.4934\n",
      "Epoch 55/100\n",
      "459/459 [==============================] - 4s 10ms/step - loss: 0.2354 - acc: 0.5877 - val_loss: 0.2596 - val_acc: 0.4915\n",
      "Epoch 56/100\n",
      "459/459 [==============================] - 4s 10ms/step - loss: 0.2349 - acc: 0.5879 - val_loss: 0.2598 - val_acc: 0.4845\n",
      "Epoch 57/100\n",
      "459/459 [==============================] - 5s 10ms/step - loss: 0.2349 - acc: 0.5894 - val_loss: 0.2596 - val_acc: 0.4870\n",
      "Epoch 58/100\n",
      "459/459 [==============================] - 5s 11ms/step - loss: 0.2344 - acc: 0.5912 - val_loss: 0.2599 - val_acc: 0.4908\n",
      "Epoch 59/100\n",
      "459/459 [==============================] - 5s 10ms/step - loss: 0.2343 - acc: 0.5869 - val_loss: 0.2604 - val_acc: 0.4858\n",
      "Epoch 60/100\n",
      "459/459 [==============================] - 4s 10ms/step - loss: 0.2342 - acc: 0.5912 - val_loss: 0.2605 - val_acc: 0.4839\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459/459 [==============================] - 4s 10ms/step - loss: 0.2341 - acc: 0.5922 - val_loss: 0.2609 - val_acc: 0.4851\n",
      "Epoch 62/100\n",
      "459/459 [==============================] - 4s 10ms/step - loss: 0.2336 - acc: 0.5922 - val_loss: 0.2603 - val_acc: 0.4902\n",
      "Epoch 63/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2334 - acc: 0.5936 - val_loss: 0.2607 - val_acc: 0.4870\n",
      "Epoch 64/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2330 - acc: 0.5937 - val_loss: 0.2612 - val_acc: 0.4870\n",
      "Epoch 65/100\n",
      "459/459 [==============================] - 4s 10ms/step - loss: 0.2333 - acc: 0.5947 - val_loss: 0.2617 - val_acc: 0.4845\n",
      "Epoch 66/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2330 - acc: 0.5956 - val_loss: 0.2612 - val_acc: 0.4896\n",
      "Epoch 67/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2325 - acc: 0.5959 - val_loss: 0.2612 - val_acc: 0.4839\n",
      "Epoch 68/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2326 - acc: 0.5978 - val_loss: 0.2611 - val_acc: 0.4858\n",
      "Epoch 69/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2321 - acc: 0.5978 - val_loss: 0.2613 - val_acc: 0.4877\n",
      "Epoch 70/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2321 - acc: 0.6024 - val_loss: 0.2613 - val_acc: 0.4877\n",
      "Epoch 71/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2322 - acc: 0.5962 - val_loss: 0.2622 - val_acc: 0.4870\n",
      "Epoch 72/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2315 - acc: 0.5958 - val_loss: 0.2617 - val_acc: 0.4921\n",
      "Epoch 73/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2313 - acc: 0.5992 - val_loss: 0.2617 - val_acc: 0.4902\n",
      "Epoch 74/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2311 - acc: 0.6013 - val_loss: 0.2629 - val_acc: 0.4858\n",
      "Epoch 75/100\n",
      "459/459 [==============================] - 4s 10ms/step - loss: 0.2304 - acc: 0.5971 - val_loss: 0.2622 - val_acc: 0.4839\n",
      "Epoch 76/100\n",
      "459/459 [==============================] - 4s 10ms/step - loss: 0.2314 - acc: 0.5967 - val_loss: 0.2620 - val_acc: 0.4902\n",
      "Epoch 77/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2308 - acc: 0.6004 - val_loss: 0.2624 - val_acc: 0.4908\n",
      "Epoch 78/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2311 - acc: 0.6026 - val_loss: 0.2623 - val_acc: 0.4934\n",
      "Epoch 79/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2304 - acc: 0.5984 - val_loss: 0.2625 - val_acc: 0.4940\n",
      "Epoch 80/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2304 - acc: 0.6060 - val_loss: 0.2626 - val_acc: 0.4972\n",
      "Epoch 81/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2309 - acc: 0.6008 - val_loss: 0.2630 - val_acc: 0.4953\n",
      "Epoch 82/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2303 - acc: 0.5985 - val_loss: 0.2626 - val_acc: 0.4946\n",
      "Epoch 83/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2293 - acc: 0.6059 - val_loss: 0.2627 - val_acc: 0.4940\n",
      "Epoch 84/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2295 - acc: 0.6051 - val_loss: 0.2629 - val_acc: 0.4972\n",
      "Epoch 85/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2296 - acc: 0.6028 - val_loss: 0.2632 - val_acc: 0.4953\n",
      "Epoch 86/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2298 - acc: 0.6027 - val_loss: 0.2634 - val_acc: 0.4972\n",
      "Epoch 87/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2288 - acc: 0.6066 - val_loss: 0.2640 - val_acc: 0.4959\n",
      "Epoch 88/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2290 - acc: 0.6040 - val_loss: 0.2635 - val_acc: 0.5028\n",
      "Epoch 89/100\n",
      "459/459 [==============================] - 4s 9ms/step - loss: 0.2284 - acc: 0.6077 - val_loss: 0.2639 - val_acc: 0.5054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f40dc4f6160>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "\n",
    "# The LSTM architecture\n",
    "regressor = Sequential()\n",
    "# First LSTM layer with Dropout regularisation\n",
    "# regressor.add(LSTM(units=25, return_sequences=True, input_shape=(240, 31)))\n",
    "regressor.add(LSTM(units=10, input_shape=(240, 31), dropout=0.1))\n",
    "\n",
    "# The output layer\n",
    "# regressor.add(LSTM(25))\n",
    "regressor.add(Dense(62, activation='relu'))\n",
    "regressor.add(Reshape((31,2)))\n",
    "# regressor.add(softmax(axis = -1))\n",
    "regressor.add(Lambda(lambda  x: softmax(x, axis = -1)))\n",
    "# Compiling the RNN\n",
    "regressor.compile(loss='mean_squared_error',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fitting to the training set\n",
    "regressor.fit(X_train,y_train,epochs=100,batch_size=10, validation_split=0.1, callbacks = [EarlyStopping(monitor='val_acc', patience=50),\n",
    "             ModelCheckpoint(filepath='../model/LSTM/best_model.h5', monitor='val_acc', save_best_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T11:41:00.556548Z",
     "start_time": "2019-03-04T11:41:00.472957Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluating our model\n",
    "predicted = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T11:41:00.559745Z",
     "start_time": "2019-03-04T11:41:00.557769Z"
    }
   },
   "outputs": [],
   "source": [
    "label = predicted > 0.5\n",
    "label = label * 1 # Convert boolean to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T11:41:00.626137Z",
     "start_time": "2019-03-04T11:41:00.561934Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.503225806451613"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sum(y_test[:, :, 1] == label[:, :, 1])/(y_test.size/2)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T11:41:00.695744Z",
     "start_time": "2019-03-04T11:41:00.630406Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = '../model/LSTM/my_model3.h5'\n",
    "regressor.save(model_name)  # creates a HDF5 file 'my_model.h5'\n",
    "del regressor  # deletes the existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T11:41:01.760910Z",
     "start_time": "2019-03-04T11:41:00.696991Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.activations import softmax\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "regressor1 = load_model(model_name, custom_objects={\"softmax\": softmax})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-04T11:41:01.868196Z",
     "start_time": "2019-03-04T11:41:01.762174Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.503225806451613"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_load = regressor1.predict(X_test)\n",
    "label_load = predicted_load > 0.5\n",
    "label_load = label_load * 1 # Convert boolean to int\n",
    "(sum(y_test[:, :, 1] == label_load[:, :, 1])/(y_test.size/2)).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet_S5",
   "language": "python",
   "name": "projet_s5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
